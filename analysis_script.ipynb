{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e3d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset chosen is: internal_test\n",
      "20\n",
      "torch.Size([8, 1, 256, 256])\n",
      "cuda\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import datasets, custom_transforms, GusarevModel, pytorch_msssim\n",
    "#import lungSegFunctions as LF\n",
    "\n",
    "# Flags:\n",
    "flag_saveReportPictures = True\n",
    "flag_saveSuppressedImages = True # set to True to produce images for further AI training\n",
    "flag_cropping = False\n",
    "\n",
    "# Paths\n",
    "PATH_SAVE_NETWORK_INTERMEDIATE = \"./runs/6LayerCNN/177-20-20/10KFold/network_intermediate_4.tar\" #\"./runs/6LayerCNN/v5_HQ_noEqualised_177-20-20/network_final.tar\"\n",
    "key_source = \"source\" # this is the dictionary key for the original radiograph in the datasets\n",
    "key_boneless = \"boneless\" # this is the dictionary key for the bone-suppressed radiograph in the datasets file\n",
    "\n",
    "# Data\n",
    "_batch_size = 8\n",
    "crop_image_spatial_size = (256,256)\n",
    "interp_mode = TF.InterpolationMode.NEAREST #BILINEAR #BILINEAR#\n",
    "\n",
    "switch = \"internal_test\"#  \"JSRT_all\" #\"QEH_onePerPatient_all\" #  \"JSRT_all\" #   \n",
    "if flag_cropping:\n",
    "    desc_crop = \"cropped\"\n",
    "else:\n",
    "    desc_crop = \"uncropped\"\n",
    "save_suppressed_desc = \"_10KFold_\"+desc_crop\n",
    "\n",
    "\n",
    "print(\"The dataset chosen is: \" + switch)\n",
    "def transform_dataset(keys_images):\n",
    "    transforms = tvtransforms.Compose([\n",
    "                                custom_transforms.ToTensor(keys_images),\n",
    "                                 custom_transforms.Resize(keys_images, crop_image_spatial_size, interp_mode),\n",
    "                                 ])\n",
    "    return transforms\n",
    "if switch == \"JSRT_all\":\n",
    "    directory_source = \"G:/DanielLam/JSRT/JSRT/\"\n",
    "    directory_boneless = \"G:/DanielLam/JSRT/BSE_JSRT/\"\n",
    "    keys_images = [key_source, key_boneless]\n",
    "    ds = datasets.JSRT_CXR(directory_source, directory_boneless, \n",
    "                           transform=transform_dataset(keys_images))\n",
    "elif switch == \"internal_test\":\n",
    "    directory_source = \"G:/DanielLam/JSRT/HQ_JSRT_and_BSE-JSRT/177-20-20 split/test/normal/\"\n",
    "    directory_boneless = \"G:/DanielLam/JSRT/HQ_JSRT_and_BSE-JSRT/177-20-20 split/test/suppressed/\"\n",
    "    keys_images = [key_source, key_boneless]\n",
    "    ds = datasets.JSRT_CXR(directory_source, directory_boneless, \n",
    "                           transform=transform_dataset(keys_images))\n",
    "elif switch == \"JSRT_NN\":\n",
    "    directory_source = \"D:/data/JSRT/JSRT_NN/\"\n",
    "    directory_boneless = None\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.JSRT_CXR(directory_source, directory_boneless, \n",
    "                           transform=transform_dataset(keys_images))\n",
    "    \n",
    "elif switch == \"QEH_full\":\n",
    "    externalTest_directory = r\"D:/data/QEH_COVID19_DATASET/CXR_pngs/\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.POLYU_COVID19_CXR_CT_Cohort1(externalTest_directory,\n",
    "                                 transform=transform_dataset(keys_images))\n",
    "elif switch == \"QEH_onePerPatient_all\":\n",
    "    externalTest_directory = r\"G:/DanielLam/QEH_COVID19_DATASET/QEH_Earliest_CXR_per_patient/all/\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.POLYU_COVID19_CXR_CT_Cohort1(externalTest_directory,\n",
    "                                 transform=transform_dataset(keys_images))\n",
    "elif switch == \"QEH_onePerPatient_HQ\":\n",
    "    externalTest_directory = r\"D:/data/QEH_COVID19_DATASET/QEH_Earliest_CXR_per_patient/high_quality/\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.POLYU_COVID19_CXR_CT_Cohort1(externalTest_directory,\n",
    "                                 transform=transform_dataset(keys_images))\n",
    "elif switch ==\"Dongrong_Test\":\n",
    "    normal_path = \"D:/data/DongrongDataSets/test/NORMAL\"\n",
    "    pneumonia_path = \"D:/data/DongrongDataSets/test/PNEUMONIA/\"\n",
    "    covid_path = \"D:/data/DongrongDataSets/test/COVID/\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.DongrongCOVIDDataset(normal_path, pneumonia_path, covid_path, \n",
    "                                       transform=transform_dataset(keys_images))\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"Dataset unknown.  Please input the details in the datasets.py file\")\n",
    "print(len(ds))\n",
    "dl = DataLoader(ds, _batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Select test \n",
    "sample = next(iter(dl))\n",
    "print(sample[key_source].shape)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 1 #torch.cuda.device_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "if (torch.cuda.is_available()):\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889c543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6-Layer MultiCNN Model.\n",
      "=> loading checkpoint './runs/6LayerCNN/177-20-20/10KFold/network_intermediate_4.tar'\n",
      "=> loaded checkpoint './runs/6LayerCNN/177-20-20/10KFold/network_intermediate_4.tar' (epoch 3450, reals shown 621000)\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "input_array_size = (_batch_size, 1, crop_image_spatial_size[0], crop_image_spatial_size[1])\n",
    "net = GusarevModel.MultilayerCNN(input_array_size)\n",
    "#net = nn.DataParallel(net, list(range(ngpu)))\n",
    "if os.path.isfile(PATH_SAVE_NETWORK_INTERMEDIATE):\n",
    "    print(\"=> loading checkpoint '{}'\".format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    checkpoint = torch.load(PATH_SAVE_NETWORK_INTERMEDIATE, map_location='cpu')\n",
    "    start_epoch = checkpoint['epochs_completed']\n",
    "    reals_shown_now = checkpoint['reals_shown']\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {}, reals shown {})\".format(PATH_SAVE_NETWORK_INTERMEDIATE, \n",
    "                                                                        start_epoch, reals_shown_now))\n",
    "else:\n",
    "    print(\"=> NO CHECKPOINT FOUND AT '{}'\" .format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    raise RuntimeError(\"No checkpoint found at specified path.\")\n",
    "\n",
    "net = net.to(device)\n",
    "# Set to testing mode\n",
    "net.eval()\n",
    "print(\"Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2702ed-37b5-4078-822f-9d76b52fc8c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-19609e7945e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Lung Segmentation Network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLungSegmentationNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcropImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboneless_minibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_cropping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_spatial_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mflag_cropping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LF' is not defined"
     ]
    }
   ],
   "source": [
    "# Lung Segmentation Network\n",
    "LS = LF.LungSegmentationNetwork(device)\n",
    "\n",
    "def cropImage(input_minibatch, boneless_minibatch, flag_cropping, image_spatial_size, interp_mode):\n",
    "    if not flag_cropping:\n",
    "        return input_minibatch, boneless_minibatch\n",
    "    else:\n",
    "        # lung segment first\n",
    "        mask, image = LS.segment(input_minibatch)\n",
    "        mask = mask.cpu() ; image = image.cpu();\n",
    "        torchresize = tvtransforms.Resize(image_spatial_size, interp_mode)\n",
    "\n",
    "        # Crop\n",
    "        inputImage = LS.crop(image, mask, image_spatial_size, interp_mode )\n",
    "        if boneless_minibatch is not None:\n",
    "            boneless = LS.crop(boneless_minibatch, mask, image_spatial_size, interp_mode)\n",
    "        else:\n",
    "            boneless = boneless_minibatch\n",
    "        return inputImage, boneless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11feb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_saveSuppressedImages:\n",
    "    path_to_save_images = Path(os.path.join(\"bone_suppressed\",switch+save_suppressed_desc))\n",
    "    path_to_save_images.mkdir(parents=True, exist_ok=True)\n",
    "    iters=0\n",
    "    for ii, data in enumerate(dl):\n",
    "        with torch.no_grad():\n",
    "            input_data = data[key_source]\n",
    "            \n",
    "            # crop processing\n",
    "            if flag_cropping:\n",
    "                if key_boneless in keys_images:\n",
    "                    inputImage, croppedBoneless = cropImage(input_data, sample[key_boneless], flag_cropping, crop_image_spatial_size, interp_mode)\n",
    "                else:\n",
    "                    inputImage, croppedBoneless = cropImage(input_data, None, flag_cropping, crop_image_spatial_size, interp_mode)\n",
    "            else:\n",
    "                inputImage = input_data\n",
    "\n",
    "            # Suppress\n",
    "            inputImage = inputImage.to(device)\n",
    "            out = net(inputImage)\n",
    "            out = out.detach()\n",
    "            out = out.cpu()\n",
    "            print(\"Batch Number:\" + str(ii))\n",
    "        \n",
    "        # Save Images\n",
    "        for iii, image in enumerate(out):\n",
    "            try:\n",
    "                savename = data[\"Patient\"][iii]+\".png\"\n",
    "            except:\n",
    "                savename = str(iters)+\".png\"\n",
    "            if switch == \"Yuhua_DDR\":\n",
    "                # flip the image back vertically\n",
    "                image = tvtransforms.functional.vflip(image)\n",
    "            vutils.save_image( image, os.path.join(path_to_save_images, savename))\n",
    "            iters+=1\n",
    "    print(\"Complete saving suppressed images\")\n",
    "else:\n",
    "    print(\"Don't save suppressed images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d741ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "save_directory = os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE)[0]\n",
    "print(save_directory)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # crop processing\n",
    "    if flag_cropping:\n",
    "        if key_boneless in keys_images:\n",
    "            inputImage, croppedBoneless = cropImage(sample[key_source], sample[key_boneless], flag_cropping, crop_image_spatial_size, interp_mode)\n",
    "        else:\n",
    "            inputImage, croppedBoneless = cropImage(sample[key_source], None, flag_cropping, crop_image_spatial_size, interp_mode)\n",
    "    else:\n",
    "        inputImage = sample[key_source]\n",
    "        \n",
    "    # Suppress\n",
    "    inputImage = inputImage.to(device)\n",
    "    out = net(inputImage)\n",
    "    out = out.detach()\n",
    "\n",
    "\n",
    "# Enter variables\n",
    "image = inputImage.cpu()\n",
    "out = out.cpu()\n",
    "if key_boneless in keys_images:\n",
    "    boneless = croppedBoneless.cpu()\n",
    "    \n",
    "for batch_idx in range(sample[key_source].shape[0]):\n",
    "    if key_boneless in keys_images:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "        ax[0].imshow(image[batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[2].imshow(boneless[batch_idx,0,:],cmap='gray')\n",
    "        ax[2].set_title(\"Ideal\")\n",
    "        ax[2].axis(\"off\")\n",
    "    else:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "        ax[0].imshow(image[batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "    if flag_saveReportPictures:\n",
    "        plt.savefig(os.path.join(save_directory, switch + \"_comparisonImages_\"+ str(batch_idx) +\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "def PSNR(image, reference, max_reference=1.):\n",
    "    \"\"\" \n",
    "    Peak Signal-to-Noise Ratio\n",
    "    Input image and reference assumed to be Torch Tensors of shape [NxCxHxW]\n",
    "    \"\"\"\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    rtMSE = torch.sqrt(MSE)\n",
    "    \n",
    "    output = 20*torch.log10(max_reference/rtMSE)\n",
    "    return np.atleast_1d(output.numpy().squeeze())\n",
    "\n",
    "def NPS():\n",
    "    \"\"\"Noise Power Spectrum\"\"\"\n",
    "    pass\n",
    "\n",
    "def SSIM(image, reference):\n",
    "    iters = 0\n",
    "    out_list = np.ndarray(image.size(0))\n",
    "    for im in image:\n",
    "        im = im.numpy()\n",
    "        im = np.moveaxis(im, 0,-1)\n",
    "        ref = reference[iters,:].numpy()\n",
    "        ref = np.moveaxis(ref, 0,-1)\n",
    "        out = skimage.metrics.structural_similarity(im, ref, multichannel=True)\n",
    "        out_list[iters]=out\n",
    "        iters+=1\n",
    "    return np.atleast_1d(out_list)\n",
    "\n",
    "def RMSE(image, reference):\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    RMSE = torch.sqrt(MSE)\n",
    "    out_list = np.squeeze(RMSE.numpy())\n",
    "    return np.atleast_1d(out_list)\n",
    "\n",
    "if \"test\" in switch:\n",
    "    psnr_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "    ssim_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "    RMSE_dict ={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "    if key_boneless in keys_images:\n",
    "        for sample in dl:\n",
    "            with torch.no_grad():\n",
    "                # crop processing\n",
    "                inputImage, croppedBoneless = cropImage(sample[key_source], sample[key_boneless], flag_cropping, crop_image_spatial_size, interp_mode)\n",
    "\n",
    "                # Suppress\n",
    "                inputImage = inputImage.to(device)\n",
    "                out = net(inputImage)\n",
    "                out = out.detach()\n",
    "\n",
    "                # Enter variables\n",
    "                image = inputImage.cpu()\n",
    "                out = out.cpu()\n",
    "                boneless = croppedBoneless.cpu()\n",
    "\n",
    "            psnr_dict[\"source_to_boneless\"].append(PSNR(image, boneless))\n",
    "            psnr_dict[\"suppressed_to_boneless\"].append(PSNR(out, boneless))\n",
    "            ssim_dict[\"source_to_boneless\"].append(SSIM(image, boneless))\n",
    "            ssim_dict[\"suppressed_to_boneless\"].append(SSIM(out, boneless))\n",
    "            RMSE_dict[\"source_to_boneless\"].append(RMSE(image, boneless))\n",
    "            RMSE_dict[\"suppressed_to_boneless\"].append(RMSE(out, boneless))\n",
    "\n",
    "print(os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall averaging\n",
    "print(\"PSNR Source to Boneless: \" + str(np.concatenate(psnr_dict[\"source_to_boneless\"]).mean()) + \"+/-\" + str(np.std(np.concatenate(psnr_dict[\"source_to_boneless\"]))))\n",
    "print(\"PSNR Suppressed to Boneless: \" + str(np.concatenate(psnr_dict[\"suppressed_to_boneless\"]).mean()) + \"+/-\" + str(np.std(np.concatenate(psnr_dict[\"suppressed_to_boneless\"]))))\n",
    "print(\"SSIM Source to Boneless: \" + str(np.concatenate(ssim_dict[\"source_to_boneless\"]).mean()) + \"+/-\" + str(np.std(np.concatenate(ssim_dict[\"source_to_boneless\"]))))\n",
    "print(\"SSIM Suppressed to Boneless: \" + str(np.concatenate(ssim_dict[\"suppressed_to_boneless\"]).mean()) + \"+/-\" + str(np.std(np.concatenate(ssim_dict[\"suppressed_to_boneless\"]))))\n",
    "print(\"RMSE Source to Boneless: \"+str(np.concatenate(RMSE_dict[\"source_to_boneless\"]).mean()) +\"+/-\"+ str(np.std(np.concatenate(RMSE_dict[\"source_to_boneless\"])))) \n",
    "print(\"RMSE Suppressed to Boneless: \"+str(np.concatenate(RMSE_dict[\"suppressed_to_boneless\"]).mean())+\"+/-\"+str(np.std(np.concatenate(RMSE_dict[\"suppressed_to_boneless\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458df7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired averaging\n",
    "def paired_t_test(array1, array2):\n",
    "    array1 = np.concatenate(array1)\n",
    "    array2 = np.concatenate(array2)\n",
    "    \n",
    "    x_diff = array1 - array2\n",
    "    s_diff = np.std(x_diff)\n",
    "    x_diff_mean = np.mean(x_diff)\n",
    "    s_x = s_diff/np.sqrt(len(x_diff))\n",
    "    \n",
    "    t_score = np.abs(x_diff_mean/s_x)\n",
    "    return t_score\n",
    "\n",
    "T_PSNR = paired_t_test(psnr_dict[\"source_to_boneless\"], psnr_dict[\"suppressed_to_boneless\"])\n",
    "T_SSIM = paired_t_test(ssim_dict[\"source_to_boneless\"], ssim_dict[\"suppressed_to_boneless\"])\n",
    "T_RMSE = paired_t_test(RMSE_dict[\"source_to_boneless\"], RMSE_dict[\"suppressed_to_boneless\"])\n",
    "\n",
    "print(\"T-score PSNR: {}\".format(T_PSNR))\n",
    "print(\"T-score SSIM: {}\".format(T_SSIM))\n",
    "print(\"T-score RMSE: {}\".format(T_RMSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
