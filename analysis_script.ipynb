{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed134f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset chosen is: external_POLYU\n",
      "1021\n",
      "torch.Size([10, 1, 440, 440])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets, transforms, GusarevModel, pytorch_msssim\n",
    "\n",
    "# Flags:\n",
    "flag_savePictures = False\n",
    "\n",
    "# Paths\n",
    "PATH_SAVE_NETWORK_INTERMEDIATE = \"./trained_network.tar\"\n",
    "key_source = \"source\" # this is the dictionary key for the original radiograph in the datasets\n",
    "key_boneless = \"boneless\" # this is the dictionary key for the bone-suppressed radiograph in the datasets file\n",
    "# Data\n",
    "_batch_size = 10\n",
    "image_spatial_size = (440,440)\n",
    "\n",
    "switch = \"external_POLYU\" #\"internal\"##\n",
    "\n",
    "print(\"The dataset chosen is: \" + switch)\n",
    "if switch == \"internal\":\n",
    "    directory_source = \"D:/data/JSRT/augmented/test/source/\"\n",
    "    directory_boneless = \"D:/data/JSRT/augmented/test/target/\"\n",
    "    keys_images = [key_source, key_boneless]\n",
    "    ds = datasets.JSRT_CXR(directory_source, directory_boneless, \n",
    "                           transform=tvtransforms.Compose([\n",
    "                                 transforms.RescalingNormalisation(keys_images,(0,1)),\n",
    "                                 transforms.Rescale(image_spatial_size, keys_images, None),\n",
    "                                 transforms.ToTensor(keys_images),\n",
    "                                 ]))\n",
    "elif switch == \"external_POLYU\":\n",
    "    externalTest_directory = \"D:/data/POLYU_COVID19_CXR_CT_Cohort1/cxr/CXR_PNG\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.POLYU_COVID19_CXR_CT_Cohort1(externalTest_directory,\n",
    "                                 transform=tvtransforms.Compose([\n",
    "                                 transforms.RescalingNormalisation(keys_images,(0,1)),\n",
    "                                 transforms.Rescale(image_spatial_size, keys_images, None),\n",
    "                                 transforms.ToTensor(keys_images),\n",
    "                                 ]))\n",
    "else:\n",
    "    raise RuntimeError(\"Dataset unknown.  Please input the details in the datasets.py file\")\n",
    "print(len(ds))\n",
    "dl = DataLoader(ds, _batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Select test \n",
    "sample = next(iter(dl))\n",
    "print(sample[key_source].shape)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 1 #torch.cuda.device_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "if (torch.cuda.is_available()):\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2566a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6-Layer MultiCNN Model.\n",
      "=> loading checkpoint './trained_network.tar'\n",
      "=> loaded checkpoint './trained_network.tar' (epoch 150, reals shown 598500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultilayerCNN(\n",
       "  (layer1): ConvBlock(\n",
       "    (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer2): ConvBlock(\n",
       "    (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer3): ConvBlock(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer4): ConvBlock(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer5): ConvBlock(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv_output): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (output_layer): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network\n",
    "input_array_size = (_batch_size, 1, image_spatial_size[0], image_spatial_size[1])\n",
    "net = GusarevModel.MultilayerCNN(input_array_size)\n",
    "#net = nn.DataParallel(net, list(range(ngpu)))\n",
    "if os.path.isfile(PATH_SAVE_NETWORK_INTERMEDIATE):\n",
    "    print(\"=> loading checkpoint '{}'\".format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    checkpoint = torch.load(PATH_SAVE_NETWORK_INTERMEDIATE, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch_next']\n",
    "    reals_shown_now = checkpoint['reals_shown']\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {}, reals shown {})\".format(PATH_SAVE_NETWORK_INTERMEDIATE, \n",
    "                                                                        start_epoch, reals_shown_now))\n",
    "else:\n",
    "    print(\"=> NO CHECKPOINT FOUND AT '{}'\" .format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    raise RuntimeError(\"No checkpoint found at specified path.\")\n",
    "\n",
    "net = net.to(device)\n",
    "# Set to testing mode\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f9d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:0\n",
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:1\n",
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:2\n",
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:3\n",
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:4\n",
      "torch.Size([10, 1, 440, 440])\n",
      "Batch Number:5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c29e331eee71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_source\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Batch Number:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\Desktop\\Deep-Learning-Models-for-bone-suppression-in-chest-radiographs\\GusarevModel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\Desktop\\Deep-Learning-Models-for-bone-suppression-in-chest-radiographs\\GusarevModel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nfdlam\\.conda\\envs\\AI\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_save_images = Path(os.path.join(\"bone_suppressed\",switch))\n",
    "path_to_save_images.mkdir(parents=True, exist_ok=True)\n",
    "iters=0\n",
    "for ii, data in enumerate(dl):\n",
    "    input_data = data[key_source].to(device)\n",
    "    out = net(input_data)\n",
    "    print(out.shape)\n",
    "    print(\"Batch Number:\" + str(ii))\n",
    "    out = out.cpu()\n",
    "    for image in out:\n",
    "        savename = str(iters)+\".png\"\n",
    "        vutils.save_image( image, os.path.join(path_to_save_images, savename))\n",
    "        iters+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0affdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "save_directory = os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE)[0]\n",
    "print(save_directory)\n",
    "for batch_idx in range(_batch_size):\n",
    "    if \"boneless\" in keys_images:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "        ax[0].imshow(sample[\"source\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[2].imshow(sample[\"boneless\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[2].set_title(\"Ideal\")\n",
    "        ax[2].axis(\"off\")\n",
    "    else:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "        ax[0].imshow(sample[\"source\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "    if flag_savePictures:\n",
    "        plt.savefig(os.path.join(save_directory, switch + \"_comparisonImages_\"+ str(batch_idx) +\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e83e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "def PSNR(image, reference, max_reference=1.):\n",
    "    \"\"\" \n",
    "    Peak Signal-to-Noise Ratio\n",
    "    Input image and reference assumed to be Torch Tensors of shape [NxCxHxW]\n",
    "    \"\"\"\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    rtMSE = torch.sqrt(MSE)\n",
    "    \n",
    "    output = 20*torch.log10(max_reference/rtMSE)\n",
    "    return output.numpy().squeeze()\n",
    "\n",
    "def NPS():\n",
    "    \"\"\"Noise Power Spectrum\"\"\"\n",
    "    \n",
    "\n",
    "def SSIM(image, reference):\n",
    "    iters = 0\n",
    "    out_list = np.ndarray(image.size(0))\n",
    "    for im in image:\n",
    "        im = im.numpy()\n",
    "        im = np.moveaxis(im, 0,-1)\n",
    "        ref = reference[iters,:].numpy()\n",
    "        ref = np.moveaxis(ref, 0,-1)\n",
    "        out = skimage.metrics.structural_similarity(im, ref, multichannel=True)\n",
    "        out_list[iters]=out\n",
    "        iters+=1\n",
    "    return out_list\n",
    "\n",
    "def MSE(image, reference):\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    out_list = np.squeeze(MSE.numpy())\n",
    "    return out_list\n",
    "\n",
    "psnr_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "ssim_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "MSE_dict ={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "if \"boneless\" in keys_images:\n",
    "    for sample in dl:\n",
    "        # Neural network\n",
    "        out = net(sample[\"source\"])\n",
    "        out = out.detach()\n",
    "        \n",
    "        psnr_dict[\"source_to_boneless\"].append(PSNR(sample[\"source\"], sample[\"boneless\"]))\n",
    "        psnr_dict[\"suppressed_to_boneless\"].append(PSNR(out, sample[\"boneless\"]))\n",
    "        ssim_dict[\"source_to_boneless\"].append(SSIM(sample[\"source\"], sample[\"boneless\"]))\n",
    "        ssim_dict[\"suppressed_to_boneless\"].append(SSIM(out, sample[\"boneless\"]))\n",
    "        MSE_dict[\"source_to_boneless\"].append(MSE(sample[\"source\"], sample[\"boneless\"]))\n",
    "        MSE_dict[\"suppressed_to_boneless\"].append(MSE(out, sample[\"boneless\"]))\n",
    "#print(\"PSNR original: {} ; after denoising: {} \".format(PSNR(sample[\"source\"], sample[\"boneless\"]).mean(), PSNR(out, sample[\"boneless\"]).mean()))\n",
    "#print(\"SSIM original: {} ; after denoising: {} \".format(SSIM(sample[\"source\"], sample[\"boneless\"]).mean(), SSIM(out, sample[\"boneless\"]).mean()))\n",
    "print(os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e157361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(psnr_dict)\n",
    "print(str(np.concatenate(psnr_dict[\"source_to_boneless\"]).mean()) + \",\" + str(np.concatenate(psnr_dict[\"suppressed_to_boneless\"]).mean()))\n",
    "print(str(np.concatenate(ssim_dict[\"source_to_boneless\"]).mean()) + \",\" + str(np.concatenate(ssim_dict[\"suppressed_to_boneless\"]).mean()))\n",
    "print(str(np.mean(np.sqrt(np.concatenate(MSE_dict[\"source_to_boneless\"])))) +\",\"+ str(np.mean(np.sqrt(np.concatenate(MSE_dict[\"suppressed_to_boneless\"])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9972154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
