{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d494e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset chosen is: external_POLYU\n",
      "1021\n",
      "torch.Size([10, 1, 256, 256])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets, transforms, GusarevModel, pytorch_msssim\n",
    "\n",
    "# Flags:\n",
    "flag_savePictures = False\n",
    "flag_saveSuppressedImages = True # set to True to produce images for further AI training\n",
    "\n",
    "# Paths\n",
    "PATH_SAVE_NETWORK_INTERMEDIATE = \"./runs/6LayerCNN/v6_GusarevCanonical/network_intermediate.tar\"\n",
    "key_source = \"source\" # this is the dictionary key for the original radiograph in the datasets\n",
    "key_boneless = \"boneless\" # this is the dictionary key for the bone-suppressed radiograph in the datasets file\n",
    "# Data\n",
    "_batch_size = 10\n",
    "image_spatial_size = (256,256)\n",
    "\n",
    "switch = \"external_POLYU\" #\"internal\"##\n",
    "\n",
    "print(\"The dataset chosen is: \" + switch)\n",
    "if switch == \"internal\":\n",
    "    directory_source = \"D:/data/JSRT/augmented/test/source/\"\n",
    "    directory_boneless = \"D:/data/JSRT/augmented/test/target/\"\n",
    "    keys_images = [key_source, key_boneless]\n",
    "    ds = datasets.JSRT_CXR(directory_source, directory_boneless, \n",
    "                           transform=tvtransforms.Compose([\n",
    "                                 transforms.RescalingNormalisation(keys_images,(0,1)),\n",
    "                                 transforms.Rescale(image_spatial_size, keys_images, None),\n",
    "                                 transforms.ToTensor(keys_images),\n",
    "                                 ]))\n",
    "elif switch == \"external_POLYU\":\n",
    "    externalTest_directory = \"D:/data/POLYU_COVID19_CXR_CT_Cohort1/cxr/CXR_PNG\"\n",
    "    keys_images = [key_source]\n",
    "    ds = datasets.POLYU_COVID19_CXR_CT_Cohort1(externalTest_directory,\n",
    "                                 transform=tvtransforms.Compose([\n",
    "                                 transforms.RescalingNormalisation(keys_images,(0,1)),\n",
    "                                 transforms.Rescale(image_spatial_size, keys_images, None),\n",
    "                                 transforms.ToTensor(keys_images),\n",
    "                                 ]))\n",
    "else:\n",
    "    raise RuntimeError(\"Dataset unknown.  Please input the details in the datasets.py file\")\n",
    "print(len(ds))\n",
    "dl = DataLoader(ds, _batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Select test \n",
    "sample = next(iter(dl))\n",
    "print(sample[key_source].shape)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 1 #torch.cuda.device_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "if (torch.cuda.is_available()):\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15e8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6-Layer MultiCNN Model.\n",
      "=> loading checkpoint './runs/6LayerCNN/v6_GusarevCanonical/network_intermediate.tar'\n",
      "=> loaded checkpoint './runs/6LayerCNN/v6_GusarevCanonical/network_intermediate.tar' (epoch 150, reals shown 598500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultilayerCNN_6LayerCNN_v2(\n",
       "  (layer1): ConvBlock_v2(\n",
       "    (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer2): ConvBlock_v2(\n",
       "    (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer3): ConvBlock_v2(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer4): ConvBlock_v2(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer5): ConvBlock_v2(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (layer6): ConvBlock_v2(\n",
       "    (conv): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (output_layer): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network\n",
    "input_array_size = (_batch_size, 1, image_spatial_size[0], image_spatial_size[1])\n",
    "net = GusarevModel.MultilayerCNN_6LayerCNN_v2(input_array_size)\n",
    "#net = nn.DataParallel(net, list(range(ngpu)))\n",
    "if os.path.isfile(PATH_SAVE_NETWORK_INTERMEDIATE):\n",
    "    print(\"=> loading checkpoint '{}'\".format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    checkpoint = torch.load(PATH_SAVE_NETWORK_INTERMEDIATE, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch_next']\n",
    "    reals_shown_now = checkpoint['reals_shown']\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {}, reals shown {})\".format(PATH_SAVE_NETWORK_INTERMEDIATE, \n",
    "                                                                        start_epoch, reals_shown_now))\n",
    "else:\n",
    "    print(\"=> NO CHECKPOINT FOUND AT '{}'\" .format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    raise RuntimeError(\"No checkpoint found at specified path.\")\n",
    "\n",
    "net = net.to(device)\n",
    "# Set to testing mode\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 256, 256])\n",
      "Batch Number:0\n",
      "torch.Size([10, 1, 256, 256])\n",
      "Batch Number:1\n",
      "torch.Size([10, 1, 256, 256])\n",
      "Batch Number:2\n"
     ]
    }
   ],
   "source": [
    "if flag_saveSuppressedImages:\n",
    "    path_to_save_images = Path(os.path.join(\"bone_suppressed\",switch))\n",
    "    path_to_save_images.mkdir(parents=True, exist_ok=True)\n",
    "    iters=0\n",
    "    for ii, data in enumerate(dl):\n",
    "        input_data = data[key_source].to(device)\n",
    "        out = net(input_data)\n",
    "        print(out.shape)\n",
    "        print(\"Batch Number:\" + str(ii))\n",
    "        out = out.cpu()\n",
    "        for image in out:\n",
    "            savename = str(iters)+\".png\"\n",
    "            vutils.save_image( image, os.path.join(path_to_save_images, savename))\n",
    "            iters+=1\n",
    "    print(\"Complete saving suppressed images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "save_directory = os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE)[0]\n",
    "print(save_directory)\n",
    "for batch_idx in range(_batch_size):\n",
    "    if \"boneless\" in keys_images:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "        ax[0].imshow(sample[\"source\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[2].imshow(sample[\"boneless\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[2].set_title(\"Ideal\")\n",
    "        ax[2].axis(\"off\")\n",
    "    else:\n",
    "        plt.figure(1)\n",
    "        fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "        ax[0].imshow(sample[\"source\"][batch_idx,0,:],cmap='gray')\n",
    "        ax[0].set_title(\"Source\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(out[batch_idx,0,:],cmap='gray')\n",
    "        ax[1].set_title(\"Suppressed\")\n",
    "        ax[1].axis(\"off\")\n",
    "    if flag_savePictures:\n",
    "        plt.savefig(os.path.join(save_directory, switch + \"_comparisonImages_\"+ str(batch_idx) +\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "def PSNR(image, reference, max_reference=1.):\n",
    "    \"\"\" \n",
    "    Peak Signal-to-Noise Ratio\n",
    "    Input image and reference assumed to be Torch Tensors of shape [NxCxHxW]\n",
    "    \"\"\"\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    rtMSE = torch.sqrt(MSE)\n",
    "    \n",
    "    output = 20*torch.log10(max_reference/rtMSE)\n",
    "    return output.numpy().squeeze()\n",
    "\n",
    "def NPS():\n",
    "    \"\"\"Noise Power Spectrum\"\"\"\n",
    "    \n",
    "\n",
    "def SSIM(image, reference):\n",
    "    iters = 0\n",
    "    out_list = np.ndarray(image.size(0))\n",
    "    for im in image:\n",
    "        im = im.numpy()\n",
    "        im = np.moveaxis(im, 0,-1)\n",
    "        ref = reference[iters,:].numpy()\n",
    "        ref = np.moveaxis(ref, 0,-1)\n",
    "        out = skimage.metrics.structural_similarity(im, ref, multichannel=True)\n",
    "        out_list[iters]=out\n",
    "        iters+=1\n",
    "    return out_list\n",
    "\n",
    "def MSE(image, reference):\n",
    "    # Assume the image \n",
    "    H = image.size(-2)\n",
    "    W = image.size(-1)\n",
    "    MSE = (1/(H*W))*torch.sum((torch.abs(image - reference))**2, (-1,-2))\n",
    "    out_list = np.squeeze(MSE.numpy())\n",
    "    return out_list\n",
    "\n",
    "psnr_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "ssim_dict={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "MSE_dict ={\"source_to_boneless\":[], \"suppressed_to_boneless\":[]}\n",
    "if \"boneless\" in keys_images:\n",
    "    for sample in dl:\n",
    "        # Neural network\n",
    "        out = net(sample[\"source\"])\n",
    "        out = out.detach()\n",
    "        \n",
    "        psnr_dict[\"source_to_boneless\"].append(PSNR(sample[\"source\"], sample[\"boneless\"]))\n",
    "        psnr_dict[\"suppressed_to_boneless\"].append(PSNR(out, sample[\"boneless\"]))\n",
    "        ssim_dict[\"source_to_boneless\"].append(SSIM(sample[\"source\"], sample[\"boneless\"]))\n",
    "        ssim_dict[\"suppressed_to_boneless\"].append(SSIM(out, sample[\"boneless\"]))\n",
    "        MSE_dict[\"source_to_boneless\"].append(MSE(sample[\"source\"], sample[\"boneless\"]))\n",
    "        MSE_dict[\"suppressed_to_boneless\"].append(MSE(out, sample[\"boneless\"]))\n",
    "#print(\"PSNR original: {} ; after denoising: {} \".format(PSNR(sample[\"source\"], sample[\"boneless\"]).mean(), PSNR(out, sample[\"boneless\"]).mean()))\n",
    "#print(\"SSIM original: {} ; after denoising: {} \".format(SSIM(sample[\"source\"], sample[\"boneless\"]).mean(), SSIM(out, sample[\"boneless\"]).mean()))\n",
    "print(os.path.split(PATH_SAVE_NETWORK_INTERMEDIATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(psnr_dict)\n",
    "print(str(np.concatenate(psnr_dict[\"source_to_boneless\"]).mean()) + \",\" + str(np.concatenate(psnr_dict[\"suppressed_to_boneless\"]).mean()))\n",
    "print(str(np.concatenate(ssim_dict[\"source_to_boneless\"]).mean()) + \",\" + str(np.concatenate(ssim_dict[\"suppressed_to_boneless\"]).mean()))\n",
    "print(str(np.mean(np.sqrt(np.concatenate(MSE_dict[\"source_to_boneless\"])))) +\",\"+ str(np.mean(np.sqrt(np.concatenate(MSE_dict[\"suppressed_to_boneless\"])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7dde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
