{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44c000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets, transforms, GusarevModel, pytorch_msssim\n",
    "\n",
    "flag_debug = True\n",
    "\n",
    "# Input Directories\n",
    "data_BSE = \"D:/data/JSRT/BSE_JSRT\"\n",
    "data_normal = \"D:/data/JSRT/JSRT\"\n",
    "\n",
    "# Image Size:\n",
    "image_spatial_size = (440,440)\n",
    "_batch_size = 4\n",
    "test_length = 10\n",
    "\n",
    "# Optimisation\n",
    "lr_ini = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "\n",
    "# Training\n",
    "num_reals_per_epoch_paper = 4000 # in Gusarev et al. 2017\n",
    "total_num_epochs_paper = 150\n",
    "num_epochs_decay_lr_paper = 100\n",
    "lr_decay_ratio = 0.25\n",
    "\n",
    "# Weight Initialisation\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight.data, 0., 0.02)\n",
    "        try:\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "        except:\n",
    "            pass\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c84354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date:\n",
    "current_date=datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Data Loader\n",
    "discriminator_keys_images = [\"source\", \"boneless\"]\n",
    "target_key = \"boneless\"\n",
    "ds = datasets.JSRT_CXR(data_normal, data_BSE,\n",
    "                         transform=tvtransforms.Compose([\n",
    "                             transforms.CLAHE(discriminator_keys_images),\n",
    "                             transforms.ZScoreNormalisation(discriminator_keys_images),\n",
    "                             transforms.RescalingNormalisation(discriminator_keys_images,(0,1)),\n",
    "                             transforms.RandomHorizontalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomVerticalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.IntensityJitter(discriminator_keys_images,source_image_key=\"source\", rescale_factor_limits=(0.75,1.0), window_motion_limits=(-1,1)),\n",
    "                             transforms.RandomIntensityComplement(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomRotation(discriminator_keys_images),\n",
    "                             transforms.Rescale(image_spatial_size, discriminator_keys_images, None),\n",
    "                             transforms.ToTensor(discriminator_keys_images),\n",
    "                             ])\n",
    "                      )\n",
    "\n",
    "# SPLIT DATA INTO TRAINING/VALIDATION SET\n",
    "lengths=(len(ds)-test_length, test_length)\n",
    "ds_training, ds_val = torch.utils.data.random_split(ds, lengths)\n",
    "\n",
    "dl_training = DataLoader(ds_training, batch_size=_batch_size,\n",
    "                         shuffle=True, num_workers=0)\n",
    "\n",
    "fixed_val_sample = next(iter(ds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3be1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of network and losses\n",
    "input_array_size = (_batch_size, 1, image_spatial_size[0], image_spatial_size[1])\n",
    "net = GusarevModel.Autoencoder(input_array_size)\n",
    "# Initialise weights\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Multi-GPU\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    net = nn.DataParallel(net, list(range(ngpu)))\n",
    "    \n",
    "\n",
    "# Optimiser\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr_ini, betas=(beta1, beta2))\n",
    "# Learning Rate Scheduler\n",
    "epoch_factor = num_reals_per_epoch_paper//len(ds_training) # need to have this factor as many epochs as that described in the paper\n",
    "total_num_epochs = total_num_epochs_paper*epoch_factor\n",
    "num_epochs_decay_lr = num_epochs_decay_lr_paper*epoch_factor\n",
    "def lambda_rule(epoch, lr_ini=lr_ini, num_epochs_decay_lr=num_epochs_decay_lr, lr_decay_ratio=lr_decay_ratio):\n",
    "    lr = lr_ini*((1-lr_decay_ratio)**(epoch//num_epochs_decay_lr))\n",
    "    return lr\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "\n",
    "# Gusarev Loss\n",
    "def criterion_Gusarev(testImage, referenceImage, alpha=0.84):\n",
    "    \"\"\"\n",
    "    Gusarev et al. 2017. Deep learning models for bone suppression in chest radiographs.  IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology.\n",
    "    \"\"\"\n",
    "    mseloss = nn.MSELoss() # L2 used for easier optimisation\n",
    "\n",
    "    msssim = pytorch_msssim.MSSSIM(window_size=11, size_average=True, channel=1, normalize=\"relu\")\n",
    "    msssim_loss = 1 - msssim(testImage, referenceImage)\n",
    "    total_loss = (1-alpha)*mseloss(testImage, referenceImage) + alpha*msssim_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd83d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2550][0/58]\tLoss_G: 0.7478\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a2d25ea775ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0miters\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mreals_shown_now\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mreals_shown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreals_shown_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "img_list = []\n",
    "loss_list = []\n",
    "reals_shown = []\n",
    "reals_shown_now = 0\n",
    "\n",
    "# For each epoch\n",
    "iters = 0\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(total_num_epochs ):\n",
    "    for i, data in enumerate(dl_training):\n",
    "        iters +=1\n",
    "        optimizer.zero_grad()\n",
    "        noisy_data = data[\"source\"].to(device)\n",
    "        cleaned_data = net(noisy_data)\n",
    "        loss = criterion_Gusarev(cleaned_data, data[target_key].to(device))\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # optimiser step along gradients\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_G: %.4f'\n",
    "                  % (epoch, total_num_epochs, i, len(dl_training),\n",
    "                     loss.item()))\n",
    "        # Record generator output\n",
    "        if (iters % 100 == 0) or ((epoch == total_num_epochs-1) and (i == len(dl_training)-1)):\n",
    "            with torch.no_grad():\n",
    "                val_cleaned = net(fixed_val_sample[\"source\"].to(device)).detach().cpu()\n",
    "            img_list_pretraining.append(vutils.make_grid(val_cleaned, padding=2, normalize=True))\n",
    "        \n",
    "        iters += 1\n",
    "        reals_shown_now += _batch_size\n",
    "        reals_shown.append(reals_shown_now)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if flag_debug and iters>=2:\n",
    "            break\n",
    "    if flag_debug and iters>=2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_training)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
