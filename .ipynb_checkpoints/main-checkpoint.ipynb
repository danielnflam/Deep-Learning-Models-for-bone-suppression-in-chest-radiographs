{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02c0ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets, transforms, GusarevModel, pytorch_msssim\n",
    "\n",
    "flag_debug = True\n",
    "\n",
    "# Input Directories\n",
    "#data_BSE = \"D:/data/JSRT/BSE_JSRT\"\n",
    "#data_normal = \"D:/data/JSRT/JSRT\"\n",
    "data_BSE = \"G:/DanielLam/JSRT/BSE_JSRT\"\n",
    "data_normal = \"G:/DanielLam/JSRT/JSRT\"\n",
    "\n",
    "# Image Size:\n",
    "image_spatial_size = (440,440)\n",
    "_batch_size = 4\n",
    "test_length = 10\n",
    "\n",
    "# Optimisation\n",
    "lr_ini = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "\n",
    "# Training\n",
    "num_reals_per_epoch_paper = 4000 # in Gusarev et al. 2017\n",
    "total_num_epochs_paper = 150\n",
    "num_epochs_decay_lr_paper = 100\n",
    "lr_decay_ratio = 0.25\n",
    "\n",
    "# Weight Initialisation\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight.data, 0., 0.02)\n",
    "        try:\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "        except:\n",
    "            pass\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9427b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date:\n",
    "current_date=datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Data Loader\n",
    "discriminator_keys_images = [\"source\", \"boneless\"]\n",
    "target_key = \"boneless\"\n",
    "ds = datasets.JSRT_CXR(data_normal, data_BSE,\n",
    "                         transform=tvtransforms.Compose([\n",
    "                             transforms.CLAHE(discriminator_keys_images),\n",
    "                             transforms.ZScoreNormalisation(discriminator_keys_images),\n",
    "                             transforms.RescalingNormalisation(discriminator_keys_images,(0,1)),\n",
    "                             transforms.RandomHorizontalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomVerticalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.IntensityJitter(discriminator_keys_images,source_image_key=\"source\", rescale_factor_limits=(0.75,1.0), window_motion_limits=(-1,1)),\n",
    "                             transforms.RandomIntensityComplement(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomRotation(discriminator_keys_images),\n",
    "                             transforms.Rescale(image_spatial_size, discriminator_keys_images, None),\n",
    "                             transforms.ToTensor(discriminator_keys_images),\n",
    "                             ])\n",
    "                      )\n",
    "\n",
    "# SPLIT DATA INTO TRAINING/VALIDATION SET\n",
    "lengths=(len(ds)-test_length, test_length)\n",
    "ds_training, ds_val = torch.utils.data.random_split(ds, lengths)\n",
    "\n",
    "dl_training = DataLoader(ds_training, batch_size=_batch_size,\n",
    "                         shuffle=True, num_workers=0)\n",
    "\n",
    "fixed_val_sample = next(iter(ds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39de422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of network and losses\n",
    "input_array_size = (_batch_size, 1, image_spatial_size[0], image_spatial_size[1])\n",
    "net = GusarevModel.Autoencoder(input_array_size)\n",
    "# Initialise weights\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Multi-GPU\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    net = nn.DataParallel(net, list(range(ngpu)))\n",
    "net = net.to(device)\n",
    "\n",
    "# Optimiser\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr_ini, betas=(beta1, beta2))\n",
    "# Learning Rate Scheduler\n",
    "epoch_factor = num_reals_per_epoch_paper//len(ds_training) # need to have this factor as many epochs as that described in the paper\n",
    "total_num_epochs = total_num_epochs_paper*epoch_factor\n",
    "num_epochs_decay_lr = num_epochs_decay_lr_paper*epoch_factor\n",
    "def lambda_rule(epoch, lr_ini=lr_ini, num_epochs_decay_lr=num_epochs_decay_lr, lr_decay_ratio=lr_decay_ratio):\n",
    "    lr = lr_ini*((1-lr_decay_ratio)**(epoch//num_epochs_decay_lr))\n",
    "    return lr\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "\n",
    "# Gusarev Loss\n",
    "def criterion_Gusarev(testImage, referenceImage, alpha=0.84):\n",
    "    \"\"\"\n",
    "    Gusarev et al. 2017. Deep learning models for bone suppression in chest radiographs.  IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology.\n",
    "    \"\"\"\n",
    "    mseloss = nn.MSELoss() # L2 used for easier optimisation\n",
    "\n",
    "    msssim = pytorch_msssim.MSSSIM(window_size=11, size_average=True, channel=1, normalize=\"relu\")\n",
    "    msssim_loss = 1 - msssim(testImage, referenceImage)\n",
    "    total_loss = (1-alpha)*mseloss(testImage, referenceImage) + alpha*msssim_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66633573",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe5b8f783906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mnoisy_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mcleaned_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoisy_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_Gusarev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculate gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Y1112\\anaconda3\\envs\\daniel\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Y1112\\anaconda3\\envs\\daniel\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[0;32m    154\u001b[0m                                    \u001b[1;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "img_list = []\n",
    "loss_list = []\n",
    "reals_shown = []\n",
    "reals_shown_now = 0\n",
    "\n",
    "# For each epoch\n",
    "iters = 0\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(total_num_epochs ):\n",
    "    for i, data in enumerate(dl_training):\n",
    "        iters +=1\n",
    "        optimizer.zero_grad()\n",
    "        noisy_data = data[\"source\"].to(device)\n",
    "        cleaned_data = net(noisy_data)\n",
    "        loss = criterion_Gusarev(cleaned_data, data[target_key].to(device))\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # optimiser step along gradients\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_G: %.4f'\n",
    "                  % (epoch, total_num_epochs, i, len(dl_training),\n",
    "                     loss.item()))\n",
    "        # Record generator output\n",
    "        if (iters % 100 == 0) or ((epoch == total_num_epochs-1) and (i == len(dl_training)-1)):\n",
    "            with torch.no_grad():\n",
    "                val_cleaned = net(fixed_val_sample[\"source\"].to(device)).detach().cpu()\n",
    "            img_list_pretraining.append(vutils.make_grid(val_cleaned, padding=2, normalize=True))\n",
    "        \n",
    "        iters += 1\n",
    "        reals_shown_now += _batch_size\n",
    "        reals_shown.append(reals_shown_now)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    \n",
    "        if flag_debug and iters>=2:\n",
    "            break\n",
    "    # LR Scheduler\n",
    "    scheduler.step()\n",
    "    if flag_debug and iters>=2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss for training\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Loss During Training\")\n",
    "plt.plot(reals_shown, loss_list)\n",
    "plt.xlabel(\"reals_shown\")\n",
    "plt.ylabel(\"Loss\")\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, current_date + \"training_loss\"+\".png\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
