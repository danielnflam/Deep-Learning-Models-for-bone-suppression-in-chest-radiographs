{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba791f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "\n",
    "import datasets, transforms\n",
    "\n",
    "# Input Directories\n",
    "data_BSE = \"D:/data/JSRT/BSE_JSRT\"\n",
    "data_normal = \"D:/data/JSRT/JSRT\"\n",
    "\n",
    "# Image Size:\n",
    "image_spatial_size = (440,440)\n",
    "\n",
    "test_length = 10\n",
    "\n",
    "# Weight Initialisation\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight.data, 0., 0.02)\n",
    "        try:\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "        except:\n",
    "            pass\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a8f4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e713a0716c4676bd14a295862694e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<datasets.JSRT_CXR at 0x22bc6d16b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current date:\n",
    "current_date=datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Data Loader\n",
    "\n",
    "discriminator_keys_images = [\"source\", \"boneless\"]\n",
    "ds = datasets.JSRT_CXR(data_normal, data_BSE,\n",
    "                         transform=tvtransforms.Compose([\n",
    "                             transforms.CLAHE(discriminator_keys_images),\n",
    "                             transforms.ZScoreNormalisation(discriminator_keys_images),\n",
    "                             transforms.RescalingNormalisation(discriminator_keys_images,(0,1)),\n",
    "                             transforms.RandomHorizontalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomVerticalFlip(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.IntensityJitter(discriminator_keys_images,source_image_key=\"source\", rescale_factor_limits=(0.75,1.0), window_motion_limits=(-1,1)),\n",
    "                             transforms.RandomIntensityComplement(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.RandomRotation(discriminator_keys_images),\n",
    "                             transforms.Rescale(image_spatial_size, discriminator_keys_images, None),\n",
    "                             transforms.ToTensor(discriminator_keys_images),\n",
    "                             ])\n",
    "                      )\n",
    "\"\"\"\n",
    "                             \n",
    "                             \"\"\"\n",
    "plt.imshow(ds[16][\"source\"][0,:])\n",
    "plt.show\n",
    "lengths=(len(ds)-test_length, test_length)\n",
    "ds_training, ds_testing = torch.utils.data.random_split(ds, lengths)\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
